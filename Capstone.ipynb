{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import mysql.connector\n",
    "from ast import literal_eval\n",
    "from tkinter.filedialog import askopenfile\n",
    "import ntpath\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_tkagg import (FigureCanvasTkAgg, \n",
    "NavigationToolbar2Tk)\n",
    "import matplotlib.pyplot as plot\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network classes\n",
    "# network_structure [[input_node_value],[layer[node_bias, node_value, node_weights ...]]...]\n",
    "# data for calculation [input_node_1_value, input_node_2_value ...]\n",
    "# data for training [[[input_node_1_value, input_node_2_value ...], [expected output1, expectout2 ...], ...]\n",
    "current_neural_network = None\n",
    "network_names = []\n",
    "def get_neural_network_names():\n",
    "    output = issue_database_command('SELECT name FROM networks')\n",
    "    name_in_output = False\n",
    "    for name_tuple in output:\n",
    "        for name in name_tuple:\n",
    "            if get_current_neural_network_name() == name:\n",
    "                name_in_output = True\n",
    "    if not name_in_output:\n",
    "        output.append(get_current_neural_network_name())\n",
    "    return output\n",
    "def get_current_neural_network_name():\n",
    "    if current_neural_network is None:\n",
    "        return 'None'\n",
    "    else:\n",
    "        return current_neural_network.name\n",
    "def sigmoid(input):\n",
    "    return (input / (1 + abs(input))) + 0.05\n",
    "    #return input\n",
    "class Node:\n",
    "    def __init__(self, bias, input_nodes, input_nodes_weights, value):\n",
    "        self.bias = bias\n",
    "        self.input_nodes = input_nodes\n",
    "        self.input_nodes_weights = input_nodes_weights\n",
    "        self.value = value\n",
    "    def calculate_value(self):\n",
    "        weighted_total = 0\n",
    "        #print('num nodes: ' + str(len(self.input_nodes)))\n",
    "        #print('num weights: ' + str(len(self.input_nodes_weights)))\n",
    "        for weight_index, node in enumerate(self.input_nodes):\n",
    "            weighted_total += float(node.value) * self.input_nodes_weights[weight_index]\n",
    "        self.value = sigmoid(weighted_total + self.bias)\n",
    "class Input_Node:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "class Node_Network:\n",
    "    def __init__(self, network_structure, name, variables, accuracy = 0):\n",
    "        self.nodes = []\n",
    "        self.name = name\n",
    "        self.variables = variables\n",
    "        self.accuracy = accuracy\n",
    "        temp = []\n",
    "        for count, layer in enumerate(network_structure):\n",
    "            if count == 0:\n",
    "                for value in layer:\n",
    "                    temp.append(Input_Node(value))\n",
    "            else:\n",
    "                for node in layer:\n",
    "                    bias = node[0]\n",
    "                    value = node[1]\n",
    "                    weights = []\n",
    "                    for node_count, value in enumerate(node):\n",
    "                        if node_count != 0 and node_count != 1:\n",
    "                            weights.append(value)\n",
    "                    temp.append(Node(bias, self.nodes[count - 1], weights, value))\n",
    "            self.nodes.append(temp)\n",
    "            temp = []\n",
    "    def calculate(self,data):\n",
    "        #print(len(data))\n",
    "        #print(len(self.nodes))\n",
    "        for value, node in enumerate(self.nodes[0]):\n",
    "            node.value = data[value]\n",
    "        for layer_count, layer in enumerate(self.nodes):\n",
    "            if layer_count != 0:\n",
    "                for node in layer:\n",
    "                    node.calculate_value()\n",
    "    def _learn(self, expected_output):\n",
    "        cost = sigmoid(self._cost(expected_output))\n",
    "        for layer_count, layer in enumerate(self.nodes):\n",
    "            if layer_count != 0:\n",
    "                for node in layer:\n",
    "                    node.bias += (random.random() - 0.5) * cost\n",
    "                    for weight_count, weight in enumerate(node.input_nodes_weights):\n",
    "                        weight += (random.random() - 0.5) * cost\n",
    "                        node.input_nodes_weights[weight_count] = weight\n",
    "                            \n",
    "        return\n",
    "    def _cost(self, expected_output):\n",
    "        output = 0\n",
    "        for count, x in enumerate(expected_output):\n",
    "            output += (self.nodes[len(self.nodes) - 1][count].value - float(x)) ** 2\n",
    "        return output\n",
    "    def get_output(self):\n",
    "        output = []\n",
    "        for node in self.nodes[len(self.nodes) - 1]:\n",
    "            output.append(node.value)\n",
    "        return output\n",
    "    # input = [[headder1, header2 ...],[column1 value, column2 value ...] ...]\n",
    "    # output = [[[input_node_1_value, input_node_2_value ...], [expected output 1, expect output 2 ...], ...]\n",
    "    def _structure_training_data(self, data):\n",
    "        data = data.data\n",
    "        data.pop(0)\n",
    "        for row in data:\n",
    "            row.pop(0)\n",
    "        output = []\n",
    "        num_inputs = int(len(self.nodes[0]) / self.variables)\n",
    "        for row_count, row in enumerate(data):\n",
    "            if row_count >= num_inputs:\n",
    "                data_inputs = []\n",
    "                num_inputs_temp = num_inputs\n",
    "                while num_inputs_temp > 0:\n",
    "                    data_inputs.extend(data[row_count - num_inputs_temp])\n",
    "                    num_inputs_temp -= 1\n",
    "                full_data = []\n",
    "                full_data.append(data_inputs)\n",
    "                full_data.append(row)\n",
    "                output.append(full_data)\n",
    "        return output\n",
    "    def train(self, raw_data):\n",
    "        data = self._structure_training_data(raw_data)\n",
    "        for dataset in data:\n",
    "            self.calculate(dataset[0])\n",
    "            fixed_data = []\n",
    "            for index, value in enumerate(dataset[1]):\n",
    "                if float(dataset[0][index]) != 0:\n",
    "                    fixed_data.append(abs(float(value) / float(dataset[0][index]))) \n",
    "                else:\n",
    "                    fixed_data.append(0)\n",
    "            self._learn(fixed_data)\n",
    "            self.update_accuracy(fixed_data)\n",
    "        load_data()\n",
    "    def get_structure(self):\n",
    "        output = []\n",
    "        for layer_count, layer in enumerate(self.nodes):\n",
    "            if layer_count == 0:\n",
    "                temp = []\n",
    "                for node in layer:\n",
    "                    temp.append(float(node.value))\n",
    "                output.append(temp)\n",
    "            else:\n",
    "                temp_layer = []\n",
    "                for node in layer:\n",
    "                    temp_node = []\n",
    "                    temp_node.append(node.bias)\n",
    "                    temp_node.append(node.value)\n",
    "                    temp_node.extend(node.input_nodes_weights)\n",
    "                    temp_layer.append(temp_node)\n",
    "                output.append(temp_layer)\n",
    "        return output\n",
    "    def update_accuracy(self, expected_output):\n",
    "        output = self.get_output()\n",
    "        output = output[0]\n",
    "        expected_output = expected_output[0]\n",
    "        if expected_output > output:\n",
    "            self.accuracy = abs(output / expected_output)\n",
    "        else:\n",
    "            self.accuracy = abs(expected_output / output)\n",
    "    def print_structure(self):\n",
    "        print('Network Name: ' + str(self.name))\n",
    "        for layer_count, layer in enumerate(self.nodes):\n",
    "            for node_count, node in enumerate(layer):\n",
    "                if layer_count > 0:\n",
    "                    print('layer: ' + str(layer_count) + ' node: ' + str(node_count) + ' value: ' + str(node.value) + ' bias: ' + str(node.bias) + ' weights: ' + str(node.input_nodes_weights))\n",
    "                else:\n",
    "                    print('layer: ' + str(layer_count) + ' node: ' + str(node_count) + ' value: ' + str(node.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tk window\n",
    "main_window = tk.Tk()\n",
    "main_window.title('Main Window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database stuff\n",
    "database_user = 'root'\n",
    "database_password = 'WGUcapstone2021'\n",
    "database_host = '127.0.0.1'\n",
    "database_name = 'neural_network_database'\n",
    "def issue_database_command(query, commit = False):\n",
    "    cnx = mysql.connector.connect(user=database_user, password=database_password,\n",
    "                              host=database_host,\n",
    "                              database=database_name)\n",
    "    cursor = cnx.cursor()\n",
    "    cursor.execute(query)\n",
    "    if commit:\n",
    "        cnx.commit()\n",
    "    output = []\n",
    "    for value in cursor:\n",
    "        output.append(value)\n",
    "    return output\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all neural network widgets\n",
    "def error_pop_up(message):\n",
    "    error_window = tk.Toplevel()\n",
    "    error_window.title('Error!')\n",
    "    error_label = tk.Label(error_window, text = message)\n",
    "    error_label.pack()\n",
    "def save_network():\n",
    "    delete_command = \"DELETE FROM networks WHERE name = '\" + current_neural_network.name + \"'\"\n",
    "    update_command = \"INSERT INTO networks (name, structre, variables, accuracy) VALUES ('\" + current_neural_network.name +\"', '\" + str(current_neural_network.get_structure()) +\"', \" + str(current_neural_network.variables) + \", \"  + str(current_neural_network.accuracy)+ ')'\n",
    "    issue_database_command(delete_command, True)\n",
    "    #print(update_command)\n",
    "    issue_database_command(update_command, True)\n",
    "def get_current_neural_network_name():\n",
    "    global current_neural_network\n",
    "    if current_neural_network != None:\n",
    "        return current_neural_network.name\n",
    "    else:\n",
    "        return 'none'\n",
    "def update_network_combobox():\n",
    "    change_neural_network_combobox['values'] = get_neural_network_names()\n",
    "def update_network_label(event):\n",
    "    if get_current_neural_network_name() != current_neural_network_string_var.get() and current_neural_network_string_var.get() != 'none':\n",
    "        load_network()\n",
    "        current_neural_network_string_var.set(\"Current Neural Network: \" + get_current_neural_network_name())\n",
    "neural_network_frame = tk.Frame(main_window)\n",
    "current_neural_network_string_var = tk.StringVar()\n",
    "current_neural_network_string_var.set(\"Current Neural Network: \" + get_current_neural_network_name())\n",
    "current_neural_network_label = tk.Label(neural_network_frame, textvariable = current_neural_network_string_var)\n",
    "change_neural_network_lablel = tk.Label(neural_network_frame, text = \"Change Neural Network:\")\n",
    "selected_network = tk.StringVar()\n",
    "change_neural_network_combobox = ttk.Combobox(neural_network_frame, textvariable = selected_network, postcommand = update_network_combobox)\n",
    "change_neural_network_combobox['values'] = get_neural_network_names()\n",
    "change_neural_network_combobox.state([\"readonly\"])\n",
    "change_neural_network_combobox.bind(\"<<ComboboxSelected>>\",update_network_label)\n",
    "change_neural_network_combobox.set('none')\n",
    "def open_new_neural_network_window():\n",
    "    create_neural_network_window = tk.Toplevel()\n",
    "    create_neural_network_window.title('Create New Neural Network')\n",
    "    network_name = tk.StringVar()\n",
    "    network_name_label = tk.Label(create_neural_network_window, text = 'Network Name: (Must be unique)')\n",
    "    input_size = tk.StringVar()\n",
    "    input_size_label = tk.Label(create_neural_network_window, text = \"Number of input data: (Must be int)\")\n",
    "    input_variables = tk.StringVar()\n",
    "    input_variables_label = tk.Label(create_neural_network_window, text = 'Number of variables: (Must be int, can only be used in datasets with same number of variables)')\n",
    "    network_name_entry = tk.Entry(create_neural_network_window, textvariable = network_name)\n",
    "    input_size_entry = tk.Entry(create_neural_network_window, textvariable = input_size)\n",
    "    input_variables_entry = tk.Entry(create_neural_network_window, textvariable = input_variables)\n",
    "    additional_layers_string_vars = []\n",
    "    additional_layers_entries = []\n",
    "    additonal_layers_labels = []\n",
    "    def add_node_layer():\n",
    "        additional_layers_string_vars.append(tk.StringVar())\n",
    "        additonal_layers_labels.append(tk.Label(create_neural_network_window, text = 'Layer ' + str(len(additional_layers_entries ) + 1) + ' number of nodes (Must be int)'))\n",
    "        additonal_layers_labels[len(additonal_layers_labels) - 1].pack()\n",
    "        additional_layers_entries.append(tk.Entry(create_neural_network_window, textvariable = additional_layers_string_vars[len(additional_layers_string_vars) - 1]))\n",
    "        additional_layers_entries[len(additional_layers_entries) - 1].pack()\n",
    "    def remove_node_layer():\n",
    "        additional_layers_entries[len(additional_layers_entries) - 1].pack_forget()\n",
    "        additonal_layers_labels[len(additonal_layers_labels) - 1].pack_forget()\n",
    "        additional_layers_string_vars.pop(len(additional_layers_string_vars) - 1)\n",
    "        additional_layers_entries.pop(len(additional_layers_entries) - 1)\n",
    "        additonal_layers_labels.pop(len(additonal_layers_labels) - 1)\n",
    "    def create_network():\n",
    "        global current_neural_network\n",
    "        if network_name.get() == 'none' or network_name.get() == '':\n",
    "            error_pop_up('invalid network name!')\n",
    "            return\n",
    "        for name in get_neural_network_names():\n",
    "            if get_neural_network_names() == name:\n",
    "                error_pop_up('invalid network name!')\n",
    "                return\n",
    "        network_structure = []\n",
    "        num_input_nodes = int(input_size.get()) * int(input_variables.get())\n",
    "        input_values = []\n",
    "        while num_input_nodes > 0:\n",
    "            input_values.append(0)\n",
    "            num_input_nodes -= 1\n",
    "        network_structure.append(input_values)\n",
    "        for count, layer in enumerate(additional_layers_string_vars):\n",
    "            layer_num_nodes = int(layer.get())\n",
    "            temp = []\n",
    "            while layer_num_nodes > 0:\n",
    "                node = [0,0]\n",
    "                if count == 0:\n",
    "                    previous_layer_num_nodes = int(input_size.get()) * int(input_variables.get())\n",
    "                else:\n",
    "                    previous_layer_num_nodes = int(additional_layers_string_vars[count - 1].get())\n",
    "                while previous_layer_num_nodes > 0:\n",
    "                    node.append(0)\n",
    "                    previous_layer_num_nodes -= 1\n",
    "                temp.append(node)\n",
    "                layer_num_nodes -= 1\n",
    "            network_structure.append(temp)\n",
    "        num_output_nodes = int(input_variables.get())\n",
    "        temp = []\n",
    "        while num_output_nodes > 0:\n",
    "            last_layer_num_nodes = int(additional_layers_string_vars[len(additional_layers_string_vars) - 1].get())\n",
    "            output_node = [0,0]\n",
    "            while last_layer_num_nodes > 0:\n",
    "                output_node.append(0)\n",
    "                last_layer_num_nodes -= 1\n",
    "            temp.append(output_node)\n",
    "            num_output_nodes -= 1\n",
    "        network_structure.append(temp)\n",
    "        current_neural_network = (Node_Network(network_structure, network_name.get().replace(' ', '_'), int(input_variables.get())))\n",
    "        change_neural_network_combobox.set(current_neural_network.name)\n",
    "        global predictions\n",
    "        global num_predictions\n",
    "        predictions = []\n",
    "        num_predictions = 0\n",
    "        create_neural_network_window.destroy()\n",
    "    add_layer_button = tk.Button(create_neural_network_window, text = 'Add New Layer', command = add_node_layer)\n",
    "    remove_layer_button = tk.Button(create_neural_network_window, text = 'Remove Layer', command = remove_node_layer)\n",
    "    create_network_button = tk.Button(create_neural_network_window, text = 'Create Network', command = create_network)\n",
    "    add_layer_button.pack()\n",
    "    remove_layer_button.pack()\n",
    "    create_network_button.pack()\n",
    "    network_name_label.pack()\n",
    "    network_name_entry.pack()\n",
    "    input_size_label.pack()\n",
    "    input_size_entry.pack()\n",
    "    input_variables_label.pack()\n",
    "    input_variables_entry.pack()\n",
    "def print_current_network():\n",
    "    current_neural_network.print_structure()\n",
    "def load_network():\n",
    "    global current_neural_network\n",
    "    name = selected_network.get()\n",
    "    new_network = issue_database_command(\"SELECT name, structre, variables, accuracy FROM networks WHERE name = '\" + name + \"'\")\n",
    "    raw_structure = new_network[0][1]\n",
    "    structure = literal_eval(raw_structure)\n",
    "    current_neural_network = Node_Network(structure, new_network[0][0], new_network[0][2], new_network[0][3])\n",
    "    global predictions\n",
    "    global num_predictions\n",
    "    predictions = []\n",
    "    num_predictions = 0\n",
    "def train_network():\n",
    "    current_neural_network.train(current_data)\n",
    "def delete_network():\n",
    "    delete_command = \"DELETE FROM networks WHERE name ='\" + current_neural_network.name + \"';\"\n",
    "    issue_database_command(delete_command, True)\n",
    "create_new_neural_network_button = tk.Button(neural_network_frame, text = 'Create new neural network', command = open_new_neural_network_window)\n",
    "print_current_network_structure_button = tk.Button(neural_network_frame, text = 'Print network structure', command = print_current_network)\n",
    "load_neural_network_button = tk.Button(neural_network_frame, text = 'Load selected neural network', command = load_network)\n",
    "save_neural_network_button = tk.Button(neural_network_frame, text = 'Save selected neural network', command = save_network)\n",
    "train_network_button = tk.Button(neural_network_frame, text= 'Train network', command = train_network)\n",
    "delete_network_button = tk.Button(neural_network_frame, text = 'Delete network', command = delete_network)\n",
    "predictions = []\n",
    "prediction_plot_frame = tk.Frame()\n",
    "pie_chart_frame = tk.Frame()\n",
    "num_predictions = 0\n",
    "def predict():\n",
    "    global predictions\n",
    "    if predictions == []:\n",
    "        data_size = len(current_neural_network.nodes[0]) / int(current_neural_network.variables)\n",
    "        while data_size > 0:\n",
    "            new_data = current_data.data[int(len(current_data.data) - data_size)][:]\n",
    "            new_data.pop(0)\n",
    "            for index, data in enumerate(new_data):\n",
    "                new_data[index] = float(data)\n",
    "            predictions.extend(new_data)\n",
    "            data_size -= 1\n",
    "    # fix prediction data\n",
    "    data_to_load = []\n",
    "    data_size = len(current_neural_network.nodes[0])\n",
    "    data_to_load = predictions[int(len(predictions) - data_size) :]\n",
    "    current_neural_network.calculate(predictions)\n",
    "    predictions.extend(current_neural_network.get_output())\n",
    "    for index in range(current_neural_network.variables):\n",
    "        predictions[len(predictions) - index - 1] = abs(current_neural_network.get_output()[index] * predictions[len(predictions) - current_neural_network.variables - index - 1])\n",
    "    global prediction_plot_frame\n",
    "    prediction_plot_frame.destroy()\n",
    "    prediction_plot_frame = tk.Frame()\n",
    "    data_to_plot = []\n",
    "    for index, value in enumerate(predictions):\n",
    "        if index % current_neural_network.variables == 0 and index > len(current_neural_network.nodes[0]) - 1:\n",
    "            data_to_plot.append(value)\n",
    "    create_bar_chart(data_to_plot, prediction_plot_frame)\n",
    "    prediction_plot_frame.pack(side = 'right')\n",
    "    global pie_chart_frame\n",
    "    pie_chart_frame.destroy()\n",
    "    pie_chart_frame = tk.Frame()\n",
    "    global num_predictions\n",
    "    num_predictions += 1\n",
    "    adjusted_accuracy = current_neural_network.accuracy ** num_predictions\n",
    "    create_pie_chart(adjusted_accuracy, pie_chart_frame)\n",
    "    pie_chart_frame.pack(side = 'left')\n",
    "predict_button = tk.Button(neural_network_frame, text = 'Predict', command = predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[[headder1, header2 ...],[column1 value, column2 value ...] ...]\n",
    "class Data:\n",
    "    def __init__(self, name, data):\n",
    "        self.name = name\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data widgets\n",
    "current_data = None\n",
    "def get_current_data_name():\n",
    "    if current_data == None:\n",
    "        return 'none'\n",
    "    else:\n",
    "        return current_data.name\n",
    "def get_current_data():\n",
    "    if current_data == None:\n",
    "        return []\n",
    "    else:\n",
    "        return current_data.data\n",
    "def get_data_names():\n",
    "    output = issue_database_command('SELECT name FROM data')\n",
    "    name_in_output = False\n",
    "    for name_tuple in output:\n",
    "        for name in name_tuple:\n",
    "            if get_current_data_name() == name:\n",
    "                name_in_output = True\n",
    "    if not name_in_output:\n",
    "        output.append(get_current_data_name())\n",
    "    return output\n",
    "def update_data_combobox():\n",
    "    change_data_combobox['values'] = get_data_names()\n",
    "def update_data_label(event):\n",
    "    if get_current_data_name() != current_data_string_var.get() and current_data_string_var.get() != 'none':\n",
    "        load_data()\n",
    "        current_data_string_var.set(\"Current Data: \" + get_current_data_name())\n",
    "data_plot_frame = tk.Frame()\n",
    "def load_data():\n",
    "    global current_data\n",
    "    name = selected_data.get()\n",
    "    new_data = issue_database_command(\"SELECT name, data FROM data WHERE name = '\" + name + \"'\")\n",
    "    raw_data = new_data[0][1]\n",
    "    data = literal_eval(raw_data)\n",
    "    current_data = Data(new_data[0][0], data)\n",
    "    data_to_plot = []\n",
    "    for index, dataset in enumerate(current_data.data):\n",
    "        if index != 0:\n",
    "            data_to_plot.append(float(dataset[1]))\n",
    "    global data_plot_frame\n",
    "    data_plot_frame.destroy()\n",
    "    data_plot_frame = tk.Frame()\n",
    "    create_plot(data_to_plot, data_plot_frame)\n",
    "    data_plot_frame.pack()\n",
    "def save_data():\n",
    "    delete_command = \"DELETE FROM data WHERE name = '\" + current_data.name + \"'\"\n",
    "    update_command = \"INSERT INTO data (name, data) VALUES ('\" + current_data.name +\"', '\" + str(current_data.data).replace(\"'\", '\"') +\"')\"\n",
    "    issue_database_command(delete_command, True)\n",
    "    issue_database_command(update_command, True)\n",
    "def upload_data():\n",
    "    global current_data\n",
    "    file_path = askopenfile(mode='r', filetypes=[('Spreadsheets', '*csv')])\n",
    "    if file_path is not None:\n",
    "        pass\n",
    "    data = []\n",
    "    for row in file_path:\n",
    "        fixed_row = row.replace(\"\\n\", \"\")\n",
    "        data.append(fixed_row.split(','))\n",
    "    name = ntpath.basename(file_path.name.split('.')[0]).replace(' ', '_')\n",
    "    file_path.close()\n",
    "    current_data = Data(name, data)\n",
    "    save_data()\n",
    "    change_data_combobox.set(name)\n",
    "data_frame = ttk.Frame()\n",
    "current_data_string_var = tk.StringVar()\n",
    "current_data_string_var.set('Current data: ' + 'None')\n",
    "current_data_label = tk.Label(data_frame, textvariable = current_data_string_var)\n",
    "selected_data= tk.StringVar()\n",
    "change_data_combobox = ttk.Combobox(data_frame, textvariable = selected_data, postcommand = update_data_combobox)\n",
    "change_data_combobox['values'] = get_data_names()\n",
    "change_data_combobox.state([\"readonly\"])\n",
    "change_data_combobox.bind(\"<<ComboboxSelected>>\",update_data_label)\n",
    "change_data_combobox.set('none')\n",
    "upload_data_button = tk.Button(data_frame, text = 'Upload data', command = upload_data)\n",
    "def print_data():\n",
    "    print(current_data.data)\n",
    "print_data_button = tk.Button(data_frame, text = 'Print data', command = print_data)\n",
    "def delete_data():\n",
    "    delete_command = \"DELETE FROM data WHERE name ='\" + current_data.name + \"';\"\n",
    "    issue_database_command(delete_command, True)\n",
    "delete_data_button = tk.Button(data_frame, text = 'Delete data', command = delete_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplot wdigets\n",
    "visual_frame = tk.Frame()\n",
    "def create_plot(data, frame):\n",
    "    fig = Figure(figsize = (5, 5), dpi = 100)\n",
    "    plot = fig.add_subplot(111).plot(data)\n",
    "    canvas = FigureCanvasTkAgg(fig,master = frame)\n",
    "    canvas.draw()\n",
    "    toolbar = NavigationToolbar2Tk(canvas, frame)\n",
    "    toolbar.update()\n",
    "    canvas.get_tk_widget().pack()\n",
    "def create_bar_chart(data, frame):\n",
    "    fig = Figure(figsize = (5, 5), dpi = 100)\n",
    "    plot = fig.add_subplot(111)\n",
    "    x_pos = [i for i, _ in enumerate(data)]\n",
    "    plot.bar(x_pos, data, color = 'blue')\n",
    "    canvas = FigureCanvasTkAgg(fig,master = frame)\n",
    "    canvas.draw()\n",
    "    toolbar = NavigationToolbar2Tk(canvas, frame)\n",
    "    toolbar.update()\n",
    "    canvas.get_tk_widget().pack()\n",
    "def create_pie_chart(data, frame):\n",
    "    fig = Figure(figsize = (5, 5), dpi = 100)\n",
    "    plot = fig.add_subplot(111)\n",
    "    data *= 100\n",
    "    anti_data = 100 - data\n",
    "    y = [anti_data, data]\n",
    "    plot.pie(y, colors = ['red', 'green'])\n",
    "    canvas = FigureCanvasTkAgg(fig,master = frame)\n",
    "    canvas.draw()\n",
    "    toolbar = NavigationToolbar2Tk(canvas, frame)\n",
    "    toolbar.update()\n",
    "    canvas.get_tk_widget().pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pack all widgets\n",
    "neural_network_frame.pack(side = 'left')\n",
    "data_frame.pack(side = 'right')\n",
    "current_neural_network_label.pack()\n",
    "change_neural_network_lablel.pack()\n",
    "change_neural_network_combobox.pack()\n",
    "create_new_neural_network_button.pack()\n",
    "#print_current_network_structure_button.pack()\n",
    "train_network_button.pack()\n",
    "predict_button.pack()\n",
    "delete_network_button.pack()\n",
    "#load_neural_network_button.pack()\n",
    "save_neural_network_button.pack()\n",
    "current_data_label.pack()\n",
    "change_data_combobox.pack()\n",
    "upload_data_button.pack()\n",
    "delete_data_button.pack()\n",
    "visual_frame.pack()\n",
    "#print_data_button.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open tk window\n",
    "main_window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892469\n"
     ]
    }
   ],
   "source": [
    "print(current_neural_network.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
